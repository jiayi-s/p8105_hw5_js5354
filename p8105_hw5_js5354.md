HW5 js5354
================
Jiayi Shen

Problem 1
---------

``` r
# create a dataframe containing all file names
participant_files = as.data.frame(list.files(path = "./data")[1:20]) 
# rename column
colnames(participant_files)[1] = 'path' 

# create a function to read in data for each subject 
read_participant_files = function (path) {
  df = 
    read.csv(str_c("./data/", path)) %>% 
    janitor::clean_names() %>% 
    as.data.frame()
  
  df
}

# saving the result as a new variable in the dataframe
participant_data = 
  map(participant_files$path, read_participant_files) %>% 
  bind_rows()

participant_data =
bind_cols(participant_files, participant_data)
```

``` r
# transform the dataframe to be longitudinal using gather
# clean up variable names
participant_data = 
participant_data %>% 
  gather(key = week, value = value, week_1:week_8) %>% 
  separate(path, into = c("group", "appendix"), sep = "_") %>% 
  separate(appendix, into = c("ID", "remove_1"), sep = 2 ) %>% 
  separate(week, into = c("remove_2", "week"), sep = "_") %>% 
  select(-remove_1, -remove_2) %>% 
  mutate(group = as.factor(group)) %>% 
  arrange(group, ID, week)
```

``` r
# plotting observations on each subject over time
participant_data %>% 
  group_by(ID) %>% 
  ggplot(aes(x = as.numeric(week), y = value, color = ID)) +
  geom_line() +
  facet_grid(.~group) +
  labs(title = "Observations on each subject over 8 weeks", 
       x = "week",
       y = "Value of observations")
```

![](p8105_hw5_js5354_files/figure-markdown_github/plotting%20observations%20on%20each%20subject%20over%20time-1.png)

On week 1, the mean observation values for the control group was 0.92 and that of the experimental group was 1.14. Though both the control arm and the experimental arm started off around 1, values in the experimental arm showed a significant increase over the 8-week course and ended up around 5.12 on average. On the other hand, the observation values of the control arm stayed relatively steady over time.

Problem 2
---------

``` r
homicide_data = read_csv("./data/homicide-data.csv")
```

`homicide-data.csv` records 52179 cases of homicide across 50 in 28 different states. For each case, there is an unique UID. In addition, reported date, characteristics of the victim (including full name, race, age and sex), geographic locations of the reported case are recorded in each entry of this dataset. Status of disposition of each case is also included, being either "Closed by arrest", "Closed without arrest" or "Open/No arrest".

``` r
#Create a city_state variable
homicide_data =
homicide_data %>% 
  mutate(city_state = str_c(city, ",", state)) %>% 
  select(-city, -state)
```

``` r
# summarize within cities to obtain the total number of homicides
homicide_data = 
homicide_data %>% 
  group_by(city_state) %>% 
  mutate(total = length(uid)) 

# the number of unsolved homicides
homicide_data = 
homicide_data %>% 
  filter(disposition == "Closed by arrest") %>% 
  group_by(city_state) %>% 
  mutate(unsolved = total - length(uid)) 

# Table that shows total and unsolved cases.
unsolved_summary = 
homicide_data %>% 
  distinct(city_state, unsolved, total) %>% 
  as.data.frame()

unsolved_summary %>% knitr::kable()
```

| city\_state       |  total|  unsolved|
|:------------------|------:|---------:|
| Albuquerque,NM    |    378|       146|
| Atlanta,GA        |    973|       373|
| Baltimore,MD      |   2827|      1825|
| Baton Rouge,LA    |    424|       196|
| Birmingham,AL     |    800|       347|
| Boston,MA         |    614|       310|
| Buffalo,NY        |    521|       319|
| Charlotte,NC      |    687|       206|
| Chicago,IL        |   5535|      4073|
| Cincinnati,OH     |    694|       309|
| Columbus,OH       |   1084|       575|
| Dallas,TX         |   1567|       754|
| Denver,CO         |    312|       169|
| Detroit,MI        |   2519|      1482|
| Durham,NC         |    276|       101|
| Fort Worth,TX     |    549|       255|
| Fresno,CA         |    487|       169|
| Houston,TX        |   2942|      1493|
| Indianapolis,IN   |   1322|       594|
| Jacksonville,FL   |   1168|       597|
| Kansas City,MO    |   1190|       486|
| Las Vegas,NV      |   1381|       572|
| Long Beach,CA     |    378|       156|
| Los Angeles,CA    |   2257|      1106|
| Louisville,KY     |    576|       261|
| Memphis,TN        |   1514|       483|
| Miami,FL          |    744|       450|
| Milwaukee,wI      |   1115|       403|
| Minneapolis,MN    |    366|       187|
| Nashville,TN      |    767|       278|
| New Orleans,LA    |   1434|       930|
| New York,NY       |    627|       243|
| Oakland,CA        |    947|       508|
| Oklahoma City,OK  |    672|       326|
| Omaha,NE          |    409|       169|
| Philadelphia,PA   |   3037|      1360|
| Phoenix,AZ        |    914|       504|
| Pittsburgh,PA     |    631|       337|
| Richmond,VA       |    429|       113|
| San Antonio,TX    |    833|       357|
| Sacramento,CA     |    376|       139|
| Savannah,GA       |    246|       115|
| San Bernardino,CA |    275|       170|
| San Diego,CA      |    461|       175|
| San Francisco,CA  |    663|       336|
| St. Louis,MO      |   1677|       905|
| Stockton,CA       |    444|       266|
| Tampa,FL          |    208|        95|
| Tulsa,OK          |    583|       193|
| Tulsa,AL          |      1|         0|
| Washington,DC     |   1345|       589|

``` r
# prop.test

prop_homicide_btm = 
  prop.test(x = unsolved_summary$unsolved[unsolved_summary$city_state =="Baltimore,MD"], 
            n = unsolved_summary$total[unsolved_summary$city_state == "Baltimore,MD"],
            alternative = "two.sided") %>% 
  broom::tidy()

# pull the estimated proportion and confidence intervals 
prop_homicide_btm["estimate"]
```

    ## # A tibble: 1 x 1
    ##   estimate
    ##      <dbl>
    ## 1    0.646

``` r
cbind(prop_homicide_btm["conf.low"], prop_homicide_btm["conf.high"])
```

    ##    conf.low conf.high
    ## 1 0.6275625 0.6631599

``` r
# Create a function to produce neat proportion test result
neat_prop_test = function (city) {
  result = 
    prop.test(x = unsolved_summary$unsolved[unsolved_summary$city_state == city],
              n = unsolved_summary$total[unsolved_summary$city_state == city], 
              alternative = "two.sided") %>% 
    broom::tidy()
  
}

# integrate the proportion test result into the summary dataframe.
unsolved_summary = 
unsolved_summary %>% 
  mutate(prop_test = map(unsolved_summary$city_state, neat_prop_test)) %>% 
  unnest()
```

    ## Warning in prop.test(x =
    ## unsolved_summary$unsolved[unsolved_summary$city_state == : Chi-squared
    ## approximation may be incorrect

``` r
# plotting the estimates and CIs for each city
unsolved_summary  %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  arrange(city_state) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point()+
  geom_errorbar(aes( ymin = conf.low, ymax = conf.high)) +
  labs(x = "City", y = "Estimated Proportions") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 
```

![](p8105_hw5_js5354_files/figure-markdown_github/plotting%20the%20estimates%20and%20CIs%20for%20each%20city-1.png)
